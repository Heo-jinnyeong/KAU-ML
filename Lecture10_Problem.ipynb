{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17cde0c3",
   "metadata": {},
   "source": [
    "# 오늘은 LeNet 구조를 만들어봅시다\n",
    "\n",
    "\n",
    "LeNet 구조는 CNN이며, 초기에 만들어진 모델입니다. \n",
    "\n",
    "2가지 모델(Sigmoid, ReLU)를 만들어 두 모델의 성능을 비교해봅시다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aff3fd",
   "metadata": {},
   "source": [
    "## 1.우선 필요 라이브러리를 import 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd17ef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798bac6b",
   "metadata": {},
   "source": [
    "## 2. 딥러닝 모델을 설계할 때 활용하는 장비 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c9880ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.11.0  Device: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5590af",
   "metadata": {},
   "source": [
    "## 3. MNIST 데이터 다운로드 \n",
    "\n",
    " 1. Training data와 Test data 분리하기\n",
    " \n",
    " 2. Training data를 Training data 와 Validation data로 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00908077",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((.5),(.5)),\n",
    "     transforms.Resize((28,28))\n",
    "    ])\n",
    "\n",
    "train_data = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train, val = torch.utils.data.random_split(train_data,[int(len(train_data)*0.8),len(train_data)-int(len(train_data)*0.8)])\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437ffb80",
   "metadata": {},
   "source": [
    "## 4. torch.nn을 이용하여 모델-1 만들기\n",
    "\n",
    "   1) 아래의 그림 중 LeNet 구조를 구현 할 것\n",
    "   \n",
    "   2) Sigmoid 활성화 함수를 이용할 것\n",
    "   \n",
    "   \n",
    "![](Comparison_image_neural_networks.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "defacffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=6, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6,out_channels=16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(in_features=16*5*5,out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120,out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84,out_features=10)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.avgp = nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.avgp(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.avgp(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26eed9",
   "metadata": {},
   "source": [
    "## 5. torch.nn을 이용하여 모델-2 만들기\n",
    "\n",
    "   LeNet 모델에서 ReLU 활성화 함수를 사용하시요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27ac70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=6, kernel_size=5,padding=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6,out_channels=16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(in_features=5*5*16,out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120,out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84,out_features=10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.avgp = nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgp(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avgp(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de556825",
   "metadata": {},
   "source": [
    "## 7. 학습 준비하기\n",
    "\n",
    "1) 1 epoch를 학습할 수 있는 함수 만들기\n",
    "\n",
    "2) Test와 Validation data의 정확도 계산할 수 있는 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06030b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_epoch(train_loader, network, loss_func, optimizer, epoch):\n",
    "    train_losses = []\n",
    "    train_correct = 0\n",
    "    log_interval = 300\n",
    "    \n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        \n",
    "\n",
    "        # 미분값의 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward propagration 계산하기.\n",
    "        outputs = network(image)\n",
    "        \n",
    "        \n",
    "        # Cross_entropy 함수를 적용하여 loss를 구하고 저장하기\n",
    "        loss = loss_func(outputs,label)\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        # training accuracy 정확도 구하기 위해 맞는 샘플 개수 세기\n",
    "        pred = torch.max(outputs,1)[1]\n",
    "        train_correct += pred.eq(label).sum()\n",
    "\n",
    "        # Gradinet 구하기\n",
    "        loss.backward()\n",
    "\n",
    "        # weight값 update 하기\n",
    "        optimizer.step()\n",
    "\n",
    "        # 학습 상황 출력\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.2f}%)]\\tLoss: {:.6f}'\n",
    "                  .format(epoch, batch_idx * len(label), len(train_loader.dataset),100. * batch_idx / len(train_loader),\n",
    "                          loss.item()))\n",
    "            \n",
    "    return train_losses, train_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3c0dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(test_loader, network, loss_func, val = False):\n",
    "    correct = 0\n",
    "    \n",
    "    test_losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (image, label) in enumerate(test_loader):\n",
    "            image, label = image.to(device), label.to(device)\n",
    "            \n",
    "\n",
    "            # Forward propagration 계산하기.\n",
    "            outputs = network(image)\n",
    "\n",
    "            # Cross_entropy 함수를 적용하여 loss를 구하기\n",
    "            loss = loss_func(outputs,label)\n",
    "            test_losses.append(loss.item())\n",
    "\n",
    "            # Batch 별로 정확도 구하기\n",
    "            pred = torch.max(outputs,1)[1]\n",
    "            correct += pred.eq(label).sum()\n",
    "\n",
    "        # 전체 정확도 구하기\n",
    "        test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "        #중간결과 출력\n",
    "        if val is True:\n",
    "                print('Validation set: Accuracy: {}/{} ({:.2f}%)\\n'\n",
    "              .format(correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset)))\n",
    "        \n",
    "        else:\n",
    "            print('Test set: Accuracy: {}/{} ({:.2f}%)\\n'\n",
    "                  .format(correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset)))\n",
    "        \n",
    "    return test_losses, test_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d73c53",
   "metadata": {},
   "source": [
    "## 8. 위 정의된 함수로 학습 함수 만들기\n",
    "\n",
    "Adam Optimizer를 사용하여 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df29783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(network, learning_rate = 0.001):\n",
    "    \n",
    "    epoches = 15\n",
    "    \n",
    "    cls_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(network.parameters(),lr=learning_rate)\n",
    "    \n",
    "    train_losses_per_epoch = []\n",
    "    test_losses_per_epoch = []\n",
    "    \n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(epoches):\n",
    "                \n",
    "        # 모델를 학습 중이라고 선언하기\n",
    "        network.train()\n",
    "        \n",
    "        train_losses, train_correct = training_epoch(train_loader,network,cls_loss,optimizer, epoch)\n",
    "        \n",
    "        # epoch 별로 loss 평균값, 정확도 구하기\n",
    "        average_loss = np.mean(train_losses)\n",
    "        train_losses_per_epoch.append(average_loss)\n",
    "        \n",
    "        train_accuracy = train_correct / len(train_loader.dataset) * 100\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        # epoch 별로 정확도 출력\n",
    "        print('\\nTraining set: Accuracy: {}/{} ({:.2f}%)'\n",
    "              .format(train_correct, len(train_loader.dataset),100. * train_correct / len(train_loader.dataset)))\n",
    "\n",
    "        \n",
    "        ### 학습 중에 test 결과 보기\n",
    "        \n",
    "        # 모델 test 중인 것을 선언하기\n",
    "        network.eval()\n",
    "        \n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            test_losses, test_accuracy = test_epoch(val_loader, network, cls_loss, True)\n",
    "\n",
    "        test_losses_per_epoch.append(np.mean(test_losses))\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        test_losses, test_accuracy = test_epoch(test_loader, network, cls_loss, False)\n",
    "        \n",
    "    return train_losses_per_epoch, test_losses_per_epoch, train_accuracies, test_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1394321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/48000 (0.00%)]\tLoss: 2.304197\n",
      "Train Epoch: 0 [19200/48000 (40.00%)]\tLoss: 2.296089\n",
      "Train Epoch: 0 [38400/48000 (80.00%)]\tLoss: 1.976232\n",
      "\n",
      "Training set: Accuracy: 14389/48000 (29.98%)\n",
      "Validation set: Accuracy: 8292/12000 (69.10%)\n",
      "\n",
      "Train Epoch: 1 [0/48000 (0.00%)]\tLoss: 1.879800\n",
      "Train Epoch: 1 [19200/48000 (40.00%)]\tLoss: 1.762307\n",
      "Train Epoch: 1 [38400/48000 (80.00%)]\tLoss: 1.738256\n",
      "\n",
      "Training set: Accuracy: 32573/48000 (67.86%)\n",
      "Validation set: Accuracy: 7993/12000 (66.61%)\n",
      "\n",
      "Train Epoch: 2 [0/48000 (0.00%)]\tLoss: 1.747828\n",
      "Train Epoch: 2 [19200/48000 (40.00%)]\tLoss: 1.664097\n",
      "Train Epoch: 2 [38400/48000 (80.00%)]\tLoss: 1.667690\n",
      "\n",
      "Training set: Accuracy: 35049/48000 (73.02%)\n",
      "Validation set: Accuracy: 9315/12000 (77.62%)\n",
      "\n",
      "Train Epoch: 3 [0/48000 (0.00%)]\tLoss: 1.668353\n",
      "Train Epoch: 3 [19200/48000 (40.00%)]\tLoss: 1.607952\n",
      "Train Epoch: 3 [38400/48000 (80.00%)]\tLoss: 1.616962\n",
      "\n",
      "Training set: Accuracy: 38316/48000 (79.82%)\n",
      "Validation set: Accuracy: 9749/12000 (81.24%)\n",
      "\n",
      "Train Epoch: 4 [0/48000 (0.00%)]\tLoss: 1.619311\n",
      "Train Epoch: 4 [19200/48000 (40.00%)]\tLoss: 1.580009\n",
      "Train Epoch: 4 [38400/48000 (80.00%)]\tLoss: 1.584035\n",
      "\n",
      "Training set: Accuracy: 39366/48000 (82.01%)\n",
      "Validation set: Accuracy: 9963/12000 (83.03%)\n",
      "\n",
      "Train Epoch: 5 [0/48000 (0.00%)]\tLoss: 1.586049\n",
      "Train Epoch: 5 [19200/48000 (40.00%)]\tLoss: 1.567860\n",
      "Train Epoch: 5 [38400/48000 (80.00%)]\tLoss: 1.571259\n",
      "\n",
      "Training set: Accuracy: 39824/48000 (82.97%)\n",
      "Validation set: Accuracy: 10066/12000 (83.88%)\n",
      "\n",
      "Train Epoch: 6 [0/48000 (0.00%)]\tLoss: 1.570491\n",
      "Train Epoch: 6 [19200/48000 (40.00%)]\tLoss: 1.558163\n",
      "Train Epoch: 6 [38400/48000 (80.00%)]\tLoss: 1.553906\n",
      "\n",
      "Training set: Accuracy: 40110/48000 (83.56%)\n",
      "Validation set: Accuracy: 10131/12000 (84.43%)\n",
      "\n",
      "Train Epoch: 7 [0/48000 (0.00%)]\tLoss: 1.563757\n",
      "Train Epoch: 7 [19200/48000 (40.00%)]\tLoss: 1.560146\n",
      "Train Epoch: 7 [38400/48000 (80.00%)]\tLoss: 1.540788\n",
      "\n",
      "Training set: Accuracy: 40272/48000 (83.90%)\n",
      "Validation set: Accuracy: 10178/12000 (84.82%)\n",
      "\n",
      "Train Epoch: 8 [0/48000 (0.00%)]\tLoss: 1.561814\n",
      "Train Epoch: 8 [19200/48000 (40.00%)]\tLoss: 1.565624\n",
      "Train Epoch: 8 [38400/48000 (80.00%)]\tLoss: 1.538744\n",
      "\n",
      "Training set: Accuracy: 40453/48000 (84.28%)\n",
      "Validation set: Accuracy: 10249/12000 (85.41%)\n",
      "\n",
      "Train Epoch: 9 [0/48000 (0.00%)]\tLoss: 1.553796\n",
      "Train Epoch: 9 [19200/48000 (40.00%)]\tLoss: 1.552764\n",
      "Train Epoch: 9 [38400/48000 (80.00%)]\tLoss: 1.546024\n",
      "\n",
      "Training set: Accuracy: 40653/48000 (84.69%)\n",
      "Validation set: Accuracy: 10304/12000 (85.87%)\n",
      "\n",
      "Train Epoch: 10 [0/48000 (0.00%)]\tLoss: 1.547189\n",
      "Train Epoch: 10 [19200/48000 (40.00%)]\tLoss: 1.544273\n",
      "Train Epoch: 10 [38400/48000 (80.00%)]\tLoss: 1.546450\n",
      "\n",
      "Training set: Accuracy: 40850/48000 (85.10%)\n",
      "Validation set: Accuracy: 10333/12000 (86.11%)\n",
      "\n",
      "Train Epoch: 11 [0/48000 (0.00%)]\tLoss: 1.539705\n",
      "Train Epoch: 11 [19200/48000 (40.00%)]\tLoss: 1.534399\n",
      "Train Epoch: 11 [38400/48000 (80.00%)]\tLoss: 1.537711\n",
      "\n",
      "Training set: Accuracy: 41075/48000 (85.57%)\n",
      "Validation set: Accuracy: 10404/12000 (86.70%)\n",
      "\n",
      "Train Epoch: 12 [0/48000 (0.00%)]\tLoss: 1.534803\n",
      "Train Epoch: 12 [19200/48000 (40.00%)]\tLoss: 1.524084\n",
      "Train Epoch: 12 [38400/48000 (80.00%)]\tLoss: 1.531065\n",
      "\n",
      "Training set: Accuracy: 41407/48000 (86.26%)\n",
      "Validation set: Accuracy: 10498/12000 (87.48%)\n",
      "\n",
      "Train Epoch: 13 [0/48000 (0.00%)]\tLoss: 1.537359\n",
      "Train Epoch: 13 [19200/48000 (40.00%)]\tLoss: 1.517684\n",
      "Train Epoch: 13 [38400/48000 (80.00%)]\tLoss: 1.526446\n",
      "\n",
      "Training set: Accuracy: 41821/48000 (87.13%)\n",
      "Validation set: Accuracy: 10602/12000 (88.35%)\n",
      "\n",
      "Train Epoch: 14 [0/48000 (0.00%)]\tLoss: 1.530190\n",
      "Train Epoch: 14 [19200/48000 (40.00%)]\tLoss: 1.519490\n",
      "Train Epoch: 14 [38400/48000 (80.00%)]\tLoss: 1.524343\n",
      "\n",
      "Training set: Accuracy: 42433/48000 (88.40%)\n",
      "Validation set: Accuracy: 10714/12000 (89.28%)\n",
      "\n",
      "Test set: Accuracy: 8890/10000 (88.90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = Model_1().to(device)\n",
    "rlt_const = training(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64815daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/48000 (0.00%)]\tLoss: 2.310854\n",
      "Train Epoch: 0 [19200/48000 (40.00%)]\tLoss: 0.914681\n",
      "Train Epoch: 0 [38400/48000 (80.00%)]\tLoss: 1.172450\n",
      "\n",
      "Training set: Accuracy: 26496/48000 (55.20%)\n",
      "Validation set: Accuracy: 6930/12000 (57.75%)\n",
      "\n",
      "Train Epoch: 1 [0/48000 (0.00%)]\tLoss: 1.323341\n",
      "Train Epoch: 1 [19200/48000 (40.00%)]\tLoss: 0.774044\n",
      "Train Epoch: 1 [38400/48000 (80.00%)]\tLoss: 1.114361\n",
      "\n",
      "Training set: Accuracy: 28018/48000 (58.37%)\n",
      "Validation set: Accuracy: 6979/12000 (58.16%)\n",
      "\n",
      "Train Epoch: 2 [0/48000 (0.00%)]\tLoss: 1.236820\n",
      "Train Epoch: 2 [19200/48000 (40.00%)]\tLoss: 0.765088\n",
      "Train Epoch: 2 [38400/48000 (80.00%)]\tLoss: 1.114369\n",
      "\n",
      "Training set: Accuracy: 28190/48000 (58.73%)\n",
      "Validation set: Accuracy: 6992/12000 (58.27%)\n",
      "\n",
      "Train Epoch: 3 [0/48000 (0.00%)]\tLoss: 1.205572\n",
      "Train Epoch: 3 [19200/48000 (40.00%)]\tLoss: 0.762643\n",
      "Train Epoch: 3 [38400/48000 (80.00%)]\tLoss: 1.101266\n",
      "\n",
      "Training set: Accuracy: 28265/48000 (58.89%)\n",
      "Validation set: Accuracy: 7003/12000 (58.36%)\n",
      "\n",
      "Train Epoch: 4 [0/48000 (0.00%)]\tLoss: 1.203835\n",
      "Train Epoch: 4 [19200/48000 (40.00%)]\tLoss: 0.756461\n",
      "Train Epoch: 4 [38400/48000 (80.00%)]\tLoss: 1.071926\n",
      "\n",
      "Training set: Accuracy: 28311/48000 (58.98%)\n",
      "Validation set: Accuracy: 6990/12000 (58.25%)\n",
      "\n",
      "Train Epoch: 5 [0/48000 (0.00%)]\tLoss: 1.162442\n",
      "Train Epoch: 5 [19200/48000 (40.00%)]\tLoss: 0.745394\n",
      "Train Epoch: 5 [38400/48000 (80.00%)]\tLoss: 1.029282\n",
      "\n",
      "Training set: Accuracy: 28350/48000 (59.06%)\n",
      "Validation set: Accuracy: 6997/12000 (58.31%)\n",
      "\n",
      "Train Epoch: 6 [0/48000 (0.00%)]\tLoss: 1.159781\n",
      "Train Epoch: 6 [19200/48000 (40.00%)]\tLoss: 0.737473\n",
      "Train Epoch: 6 [38400/48000 (80.00%)]\tLoss: 1.006263\n",
      "\n",
      "Training set: Accuracy: 28403/48000 (59.17%)\n",
      "Validation set: Accuracy: 7017/12000 (58.47%)\n",
      "\n",
      "Train Epoch: 7 [0/48000 (0.00%)]\tLoss: 1.168397\n",
      "Train Epoch: 7 [19200/48000 (40.00%)]\tLoss: 0.736635\n",
      "Train Epoch: 7 [38400/48000 (80.00%)]\tLoss: 0.996657\n",
      "\n",
      "Training set: Accuracy: 28419/48000 (59.21%)\n",
      "Validation set: Accuracy: 7017/12000 (58.47%)\n",
      "\n",
      "Train Epoch: 8 [0/48000 (0.00%)]\tLoss: 1.166212\n",
      "Train Epoch: 8 [19200/48000 (40.00%)]\tLoss: 0.734501\n",
      "Train Epoch: 8 [38400/48000 (80.00%)]\tLoss: 1.039050\n",
      "\n",
      "Training set: Accuracy: 28425/48000 (59.22%)\n",
      "Validation set: Accuracy: 6989/12000 (58.24%)\n",
      "\n",
      "Train Epoch: 9 [0/48000 (0.00%)]\tLoss: 1.172616\n",
      "Train Epoch: 9 [19200/48000 (40.00%)]\tLoss: 0.735872\n",
      "Train Epoch: 9 [38400/48000 (80.00%)]\tLoss: 0.980257\n",
      "\n",
      "Training set: Accuracy: 28472/48000 (59.32%)\n",
      "Validation set: Accuracy: 7016/12000 (58.47%)\n",
      "\n",
      "Train Epoch: 10 [0/48000 (0.00%)]\tLoss: 1.154147\n",
      "Train Epoch: 10 [19200/48000 (40.00%)]\tLoss: 0.729058\n",
      "Train Epoch: 10 [38400/48000 (80.00%)]\tLoss: 0.997764\n",
      "\n",
      "Training set: Accuracy: 28478/48000 (59.33%)\n",
      "Validation set: Accuracy: 7007/12000 (58.39%)\n",
      "\n",
      "Train Epoch: 11 [0/48000 (0.00%)]\tLoss: 1.157211\n",
      "Train Epoch: 11 [19200/48000 (40.00%)]\tLoss: 0.736703\n",
      "Train Epoch: 11 [38400/48000 (80.00%)]\tLoss: 0.972296\n",
      "\n",
      "Training set: Accuracy: 28476/48000 (59.33%)\n",
      "Validation set: Accuracy: 7030/12000 (58.58%)\n",
      "\n",
      "Train Epoch: 12 [0/48000 (0.00%)]\tLoss: 1.167218\n",
      "Train Epoch: 12 [19200/48000 (40.00%)]\tLoss: 0.719880\n",
      "Train Epoch: 12 [38400/48000 (80.00%)]\tLoss: 0.996809\n",
      "\n",
      "Training set: Accuracy: 28487/48000 (59.35%)\n",
      "Validation set: Accuracy: 7019/12000 (58.49%)\n",
      "\n",
      "Train Epoch: 13 [0/48000 (0.00%)]\tLoss: 1.151597\n",
      "Train Epoch: 13 [19200/48000 (40.00%)]\tLoss: 0.719894\n",
      "Train Epoch: 13 [38400/48000 (80.00%)]\tLoss: 0.980824\n",
      "\n",
      "Training set: Accuracy: 28498/48000 (59.37%)\n",
      "Validation set: Accuracy: 7020/12000 (58.50%)\n",
      "\n",
      "Train Epoch: 14 [0/48000 (0.00%)]\tLoss: 1.154877\n",
      "Train Epoch: 14 [19200/48000 (40.00%)]\tLoss: 0.719611\n",
      "Train Epoch: 14 [38400/48000 (80.00%)]\tLoss: 0.981825\n",
      "\n",
      "Training set: Accuracy: 28515/48000 (59.41%)\n",
      "Validation set: Accuracy: 6992/12000 (58.27%)\n",
      "\n",
      "Test set: Accuracy: 5909/10000 (59.09%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = Model_2().to(device)\n",
    "rlt_const = training(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791b1471",
   "metadata": {},
   "source": [
    "## 9. 두모델의 성능을 비교하시오"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f8156f",
   "metadata": {},
   "source": [
    "정답) \n",
    "model2가 loss값은 작지만, 최종 정확도에서 59.09%로 나와, 88.90%가 나온 model1보다는 성능이 부족하다고 할 수 있다.\n",
    "따라서 LeNet에서는 활성함수를 sigmoid를 사용하여 모델의 성능을 높일 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
